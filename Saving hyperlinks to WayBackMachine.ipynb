{"cells":[{"cell_type":"markdown","metadata":{"id":"ZylQBLWnqJFZ"},"source":["Sources: https://www.holisticseo.digital/python-seo/internet-archive/,\n","https://pypi.org/project/waybackpy/"]},{"cell_type":"markdown","source":["This code:\n","1.Installs the `waybackpy` library for accessing the Wayback Machine's archiving services.\n","2. Imports necessary libraries, including pandas for data manipulation and time for timing operations.\n","3. Defines a user agent string to mimic a web browser for requests.\n","4. Connects to Google Drive to access files stored there.\n","5. Prompts the user to enter the full path of an Excel file containing URLs.\n","6. Loads the specified Excel file into a pandas DataFrame.\n","7. Adds a new column called 'Archived URL' to the DataFrame to store archived links.\n","8. Iterates through each URL in the DataFrame, checking if it is already archived; if not, it attempts to archive it.\n","9. Implements a rate limit of 15 URLs per minute to avoid exceeding the Wayback Machine's request limits.\n","10. Saves the updated DataFrame with archived URLs into a new Excel file named \"Updated_Archive_Links.xlsx\" in the same folder where original file is stored on Google Drive."],"metadata":{"id":"ZgrpAdGE3ZKD"}},{"cell_type":"markdown","metadata":{"id":"EMjde6RTqH0O"},"source":["# Connecting GoogleDrive and opening your Excel file. For smooth data loading and processing it should have column with the hyperlinks called \"URL\"\n","\n","This code works best in GoogleColab interface"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24329,"status":"ok","timestamp":1724142146936,"user":{"displayName":"Research Center","userId":"03773296375181742265"},"user_tz":-180},"id":"uAIJzeM6qxJ7","outputId":"04699369-5316-4a3f-a70c-b23ddf5f904c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: waybackpy in /usr/local/lib/python3.10/dist-packages (3.0.6)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from waybackpy) (8.1.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from waybackpy) (2.31.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from waybackpy) (2.0.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->waybackpy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->waybackpy) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->waybackpy) (2024.7.4)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Insert beliw this code full path to the file on Google Drive: /content/drive/MyDrive/Analytical Centre DM/DM and CIR/Religion DeepDive/Тест архівування посилань.xlsx\n","Folder: /content/drive/MyDrive/Analytical Centre DM/DM and CIR/Religion DeepDive\n","Filename: Тест архівування посилань.xlsx\n","5 links processed, 1 remaining.\n","6 links processed, 0 remaining.\n","Archiving process completed. Dataframe saved to 'Updated_Archive_Links.xlsx' in the initial folder.\n"]}],"source":["# Downloading and importing libraries\n","!pip install waybackpy\n","\n","import pandas as pd\n","import time\n","from waybackpy import WaybackMachineCDXServerAPI, WaybackMachineSaveAPI\n","import os\n","\n","# Define the user agent string (this can be customized)\n","user_agent = \"Mozilla/5.0 (Windows NT 5.1; rv:40.0) Gecko/20100101 Firefox/40.0\"\n","\n","# Connect to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#File path\n","file_path = str(input(\"Insert below this code full path to the file on Google Drive: \"))\n","\n","# Split the path into folder and filename\n","folder, filename = os.path.split(file_path)\n","\n","print(\"Folder:\", folder)\n","print(\"Filename:\", filename)\n","\n","\n","# Load the dataframe\n","df = pd.read_excel(os.path.join(folder, filename))\n","\n","# Create a new column 'Archived URL' in the dataframe\n","# Create a new column 'Archived URL' in the dataframe\n","df['Archived URL'] = None\n","\n","# Track the number of links saved in the current minute and overall progress\n","links_saved_in_minute = 0\n","total_links = len(df)\n","processed_links = 0\n","start_time = time.time()\n","\n","# Iterate over each URL in the dataframe\n","for i, row in df.iterrows():\n","    url = row['URL']\n","\n","    try:\n","        # Check if the URL has already been archived\n","        cdx_api = WaybackMachineCDXServerAPI(url, user_agent)\n","        newest_snapshot = cdx_api.newest()\n","\n","        if newest_snapshot:\n","            df.at[i, 'Archived URL'] = newest_snapshot.archive_url\n","        else:\n","            # If not archived, attempt to archive it now\n","            save_api = WaybackMachineSaveAPI(url, user_agent)\n","            saved_url = save_api.save()\n","            df.at[i, 'Archived URL'] = saved_url\n","\n","            # Update the count of links saved in the current minute\n","            links_saved_in_minute += 1\n","\n","    except Exception as e:\n","        print(f\"Error processing URL '{url}': {str(e)}\")\n","        df.at[i, 'Archived URL'] = \"Failed to save. Try to do it manually or with another archiving tool\"\n","\n","    # Increment the processed links count\n","    processed_links += 1\n","\n","    # Print status every 5 iterations\n","    if processed_links % 5 == 0 or processed_links == total_links:\n","        print(f\"{processed_links} links processed, {total_links - processed_links} remaining.\")\n","\n","    # Check if the limit of 15 links per minute has been reached\n","    if links_saved_in_minute >= 15:\n","        elapsed_time = time.time() - start_time\n","        if elapsed_time < 60:\n","            sleep_time = 61 - elapsed_time\n","            print(f\"Reached limit of 15 links in a minute. Sleeping for {sleep_time:.2f} seconds...\")\n","            time.sleep(sleep_time)\n","\n","        # Reset the count and start time for the next minute\n","        links_saved_in_minute = 0\n","        start_time = time.time()\n","\n","# Save the updated dataframe to a new Excel file\n","df.to_excel(os.path.join(folder, \"Updated_Archive_Links.xlsx\"), index=False)\n","\n","print(\"Archiving process completed. Dataframe saved to 'Updated_Archive_Links.xlsx' in the initial folder.\")"]}],"metadata":{"colab":{"provenance":[{"file_id":"1W42Geipoqp8dI_NYPx9yDQhrIOOV6ynF","timestamp":1724142244355}],"authorship_tag":"ABX9TyOa9SLXHWkyFU2T7IO8tSP9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}